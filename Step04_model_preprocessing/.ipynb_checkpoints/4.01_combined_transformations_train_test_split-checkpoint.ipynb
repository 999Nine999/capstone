{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steb04a Combined Transformations and Train, Test, Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('../data/processed/pitchers/pitchers_with_batters_2019.pickle','rb')\n",
    "pb = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's review all columns for final decisions of inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two null values in if and of alignment\n",
    "Will replace with standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb.if_fielding_alignment = pb.if_fielding_alignment.fillna('Standard')\n",
    "pb.of_fielding_alignment = pb.of_fielding_alignment.fillna('Standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that are either duplicative or are not known before the pitch is thrown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = pb.drop(columns = ['game_date_x', 'sv_id', 'batter_id', 'home_team', 'release_speed', 'zone', \n",
    "                        'on_3b', 'on_2b', 'on_1b', 'release_spin_rate', 'game_date_y', 'shift_date', \n",
    "                        'player_name', 'hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pb.drop(columns = 'pitch_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pb.pitch_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['stand', 'if_fielding_alignment', 'of_fielding_alignment', 'balls_strikes', 'all_runners']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features that are already standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = ['nats_home1_away0', 'ba', 'slg', 'iso', 'babip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define MinMax Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = []\n",
    "non_nums = cats + formatted\n",
    "\n",
    "for c in X.columns:\n",
    "    if c not in non_nums:\n",
    "        minmax.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first', handle_unknown='error', sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe_ar = ohe.fit_transform(X[cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = ['stand_r1', 'if_standard', 'if_strategic', 'of_strategic', \n",
    "        '0_1', '0_2', '1_0', '1_1', '1_2', '2_0', '2_1', '2_2', '3_0', '3_1', '3_2',\n",
    "        'fb:0_sb:0_tb:1', 'fb:0_sb:1_tb:0', 'fb:0_sb:1_tb:1', 'fb:1_sb:0_tb:0', \n",
    "        'fb:1_sb:0_tb:1', 'fb:1_sb:1_tb:0', 'fb:1_sb:1_tb:1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df = pd.DataFrame(data = X_ohe_ar, columns = ohe_cols).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mm = mm.fit_transform(X[minmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = pd.DataFrame(columns = minmax, data = X_mm).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DF for features that are already standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = X[formatted].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Processed X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df.shape, mm_df.shape, X[formatted].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_df.shape[1] + mm_df.shape[1] + X[formatted].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trans = pd.DataFrame()\n",
    "X_trans = pd.concat([mm_df, ohe_df], axis = 1)\n",
    "X_trans = X_trans.drop(columns = 'index')\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process y data where each pitch type is its own class (all classes or ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_type_dict = {'FF': 0, 'FC': 1, 'SL': 2, 'CU': 3, 'CH': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_ac = y\n",
    "\n",
    "for pitch in pitch_type_dict:\n",
    "#     print(pitch, pitch_type_dict[pitch])\n",
    "    y_ord_ac = np.where(y_ord_ac == pitch, pitch_type_dict[pitch], y_ord_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_ac[:10], y[:10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process y data grouping pitches into three classes (or 3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_3_types = {'FF': 0, 'FC': 1, 'SL': 1, 'CU': 1, 'CH':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_3c = y\n",
    "\n",
    "for pitch in pitch_3_types:\n",
    "#     print(pitch, pitch_type_dict[pitch])\n",
    "    y_ord_3c = np.where(y == pitch, pitch_3_types[pitch], y_ord_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_3c[:10], y[:10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process y data grouping pitches into two classes (or 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_2_types = {'FF': 0, 'FC': 1, 'SL': 1, 'CU': 1, 'CH':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_2c = y\n",
    "\n",
    "for pitch in pitch_3_types:\n",
    "#     print(pitch, pitch_type_dict[pitch])\n",
    "    y_ord_2c = np.where(y == pitch, pitch_2_types[pitch], y_ord_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ord_2c[:10], y[:10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All classes flavor\n",
    "X_train_ac, X_test_ac, y_train_ac, y_test_ac = train_test_split(X_trans,\n",
    "                                                                y_ord_ac,\n",
    "                                                                test_size = .3,\n",
    "                                                                random_state = 31,\n",
    "                                                                shuffle = True,\n",
    "                                                                stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3c, X_test_3c, y_train_3c, y_test_3c = train_test_split(X_trans,\n",
    "                                                                y_ord_3c,\n",
    "                                                                test_size = .3,\n",
    "                                                                random_state = 31,\n",
    "                                                                shuffle = True,\n",
    "                                                                stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2c, X_test_2c, y_train_2c, y_test_2c = train_test_split(X_trans,\n",
    "                                                                y_ord_2c,\n",
    "                                                                test_size = .3,\n",
    "                                                                random_state = 31,\n",
    "                                                                shuffle = True,\n",
    "                                                                stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All classes flavor\n",
    "filepath = '../data/train_test_split/scherzer/2019_all_classes/'\n",
    "\n",
    "pickle_out = open(filepath + 'X_train_ac.pickle', 'wb')\n",
    "pickle.dump(X_train_ac, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'X_test_ac.pickle', 'wb')\n",
    "pickle.dump(X_test_ac, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_train_ac.pickle', 'wb')\n",
    "pickle.dump(y_train_ac, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_test_ac.pickle', 'wb')\n",
    "pickle.dump(y_test_ac, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three(3) classes flavor\n",
    "filepath = '../data/train_test_split/scherzer/2019_three_classes/'\n",
    "\n",
    "pickle_out = open(filepath + 'X_train_3c.pickle', 'wb')\n",
    "pickle.dump(X_train_3c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'X_test_3c.pickle', 'wb')\n",
    "pickle.dump(X_test_3c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_train_3c.pickle', 'wb')\n",
    "pickle.dump(y_train_3c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_test_3c.pickle', 'wb')\n",
    "pickle.dump(y_test_3c, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three(3) classes flavor\n",
    "filepath = '../data/train_test_split/scherzer/2019_two_classes/'\n",
    "\n",
    "pickle_out = open(filepath + 'X_train_2c.pickle', 'wb')\n",
    "pickle.dump(X_train_2c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'X_test_2c.pickle', 'wb')\n",
    "pickle.dump(X_test_2c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_train_2c.pickle', 'wb')\n",
    "pickle.dump(y_train_2c, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(filepath + 'y_test_2c.pickle', 'wb')\n",
    "pickle.dump(y_test_2c, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
