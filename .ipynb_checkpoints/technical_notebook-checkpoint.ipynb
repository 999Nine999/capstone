{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Notebook\n",
    "This notebook highlights the technical elements of this experiment to include six major steps:\n",
    "- Acquisition, cleaning, and feature engineering for MLB pitchers\n",
    "- Acquisition, cleaning, and feature engineering for MLB batters\n",
    "- Joining pitcher and batter data\n",
    "- Preprocessing for modeling\n",
    "- Model selection and hyperparameter tuning\n",
    "- Model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder, StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from yellowbrick.classifier import ConfusionMatrix, confusion_matrix\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "from yellowbrick.features import RadViz\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 and 2: Pitcher and batter data acquisition\n",
    "The process for scraping pitcher and batter data are similar.  In the interest of brevity, the code for scraping batter data is included below.  The process for pitchers is identical aside from the urls referenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that modifies baseball savant url for each team in order to get all batter data per date in 2019\n",
    "def url_per_team(front_url, team, back_url):\n",
    "    team_url = front_url + team + back_url\n",
    "    team_url = team_url.replace(' ', '')\n",
    "    return team_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create url components required to reference baseballsavant's data\n",
    "front_url = 'https://baseballsavant.mlb.com/statcast_search/csv?all=true&\\\n",
    "                hfPT=&hfAB=&hfBBT=&hfPR=&hfZ=&stadium=&hfBBL=&hfNewZones=&hfGT=R%7C&hfC=&hfSea=2019%7C&\\\n",
    "                hfSit=&player_type=batter&hfOuts=&opponent=&pitcher_throws=&batter_stands=&hfSA=&\\\n",
    "                game_date_gt=&game_date_lt=&hfInfield=&team='\n",
    "\n",
    "back_url = '&position=&hfOutfield=&hfRO=&\\\n",
    "                home_road=&hfFlag=&hfPull=&metric_1=&hfInn=&min_pitches=0&min_results=0&\\\n",
    "                group_by=name-date&sort_col=ba&player_event_sort=h_launch_speed&sort_order=desc&\\\n",
    "                min_pas=0&chk_stats_pa=on&chk_stats_abs=on&chk_stats_hits=on&chk_stats_singles=on&\\\n",
    "                chk_stats_dbls=on&chk_stats_triples=on&chk_stats_hrs=on&chk_stats_so=on&\\\n",
    "                chk_stats_k_percent=on&chk_stats_bb=on&chk_stats_bb_percent=on&chk_stats_babip=on&\\\n",
    "                chk_stats_iso=on&chk_stats_ba=on&chk_stats_xba=on&chk_stats_xbadiff=on&chk_stats_slg=on&\\\n",
    "                chk_stats_xslg=on&chk_stats_xslgdiff=on&chk_stats_woba=on&chk_stats_xwoba=on&chk_stats_wobadiff=on&'\n",
    "\n",
    "teams = ['LAA', 'HOU', 'OAK', 'TOR', 'ATL', 'MIL', 'STL', 'CHC', 'ARI', 'LAD', 'SF', 'CLE', 'SEA', \\\n",
    "            'MIA', 'NYM', 'WSH', 'BAL', 'SD', 'PHI', 'PIT', 'TEX', 'TB', 'BOS', 'CIN', 'COL', 'KC', \\\n",
    "            'DET', 'MIN', 'CWS', 'NYY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of team names and baseaball savant urls\n",
    "team_urls_dict = {}\n",
    "\n",
    "for team in teams:\n",
    "    name_lower = team.lower()\n",
    "    team_url = url_per_team(front_url, team, back_url)\n",
    "    team_urls_dict.update({name_lower: team_url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes a team name and url\n",
    "# It captues csv batter data for that team\n",
    "# Adds a column with the team name\n",
    "# Saves df to a dataframe\n",
    "# It returns the team id (lowercase) and the batters data dataframe dictionary\n",
    "\n",
    "def get_batters_data(team, url):\n",
    "    batter_df = pd.read_csv(url)\n",
    "    batter_df['team'] = team\n",
    "    return team, batter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionary with which to save all batter dataframes acquired from baseball savant\n",
    "batter_df_dict = {}\n",
    "teams_left = 29\n",
    "\n",
    "for team in team_urls_dict:\n",
    "    team, batter_df = get_batters_data(team, team_urls_dict[team])\n",
    "    batter_df_dict.update({team: batter_df})\n",
    "    print('Just snagged batter data for {}, {} of 30 teams remaining...'.format(team, teams_left))\n",
    "    teams_left -= 1\n",
    "    time.sleep(30)\n",
    "    \n",
    "# # After snagging data for half the league (15 teams) hit a 502 error\n",
    "# # Disabling code so webscraping does not rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through batter_df_dict and concatitate all dfs into one master file\n",
    "for team in batter_df_dict.keys():\n",
    "    if team == 'laa':\n",
    "        all_batters_df = batter_df_dict[team]\n",
    "    else:\n",
    "        all_batters_df = pd.concat([all_batters_df, batter_df_dict[team]])\n",
    "        \n",
    "# After exporting pickled data, we move on to step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Batter KMeans Clusters and Join pitcher/batter data\n",
    "Here we create KMeans clusters for batters and join all our data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After importing the batter data, we create KMeans Cluster assigining each hitter into one of four groups\n",
    "pca = PCA(n_components=2, random_state=31)\n",
    "X_redux = pca.fit_transform(X_ss)\n",
    "\n",
    "km = KMeans(n_clusters=4, random_state=31)\n",
    "clusters = km.fit(X_redux)\n",
    "labels = km.labels_\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(16, 8))\n",
    "fig = sns.scatterplot(x = X_redux[:,0], \n",
    "                y = X_redux[:,1], \n",
    "                hue = labels, \n",
    "                palette = 'colorblind').set_title('K-Means Clustering for MLB Hitters');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to join pitcher and batter data\n",
    "pb = pitchers.merge(batters, \n",
    "                   how = 'inner', \n",
    "                   left_on = ['game_date', 'batter'], \n",
    "                   right_on = ['shift_date', 'player_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Preprocessing and Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In preparation for modeling we preprocess with one hot encoding and minmax scaling\n",
    "\n",
    "# Define categorical variables\n",
    "cats = ['stand', 'if_fielding_alignment', 'of_fielding_alignment', 'balls_strikes', 'all_runners']\n",
    "\n",
    "# Define columns already standardized\n",
    "formatted = ['nats_home1_away0', 'ba', 'slg', 'iso', 'babip']\n",
    "\n",
    "# Define minmax variables\n",
    "minmax = []\n",
    "non_nums = cats + formatted\n",
    "\n",
    "for c in X.columns:\n",
    "    if c not in non_nums:\n",
    "        minmax.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fitting all transformations, the target data is processed to represent three pitch types\n",
    "pitch_3_types = {'FF': 0, 'FC': 1, 'SL': 1, 'CU': 1, 'CH':2}\n",
    "y_ord_3c = y\n",
    "\n",
    "for pitch in pitch_3_types:\n",
    "#     print(pitch, pitch_type_dict[pitch])\n",
    "    y_ord_3c = np.where(y == pitch, pitch_3_types[pitch], y_ord_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split data.  In the 4.01 notebook you will nice three train test splits.  These include different\n",
    "# binning of the target data as different train sets were assessed prior to final selection of three classes\n",
    "X_train_3c, X_test_3c, y_train_3c, y_test_3c = train_test_split(X_trans,\n",
    "                                                                y_ord_3c,\n",
    "                                                                test_size = .3,\n",
    "                                                                random_state = 31,\n",
    "                                                                shuffle = True,\n",
    "                                                                stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the imbalance of pitch types in the target data, the majority class is undersampled\n",
    "under = RandomUnderSampler(sampling_strategy='auto')\n",
    "X_under, y_under = under.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to track model performance\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy model\n",
    "dc = DummyClassifier(strategy = 'most_frequent')\n",
    "dc.fit(X_under, y_under)\n",
    "dc.score(X_under, y_under)\n",
    "results.update({'Dummy': [dc.score(X_train, y_train), 0]})\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state = 31, max_iter = 1000)\n",
    "lr.fit(X_under, y_under)\n",
    "lr.score(X_under, y_under)\n",
    "results.update({'LogReg': [lr.score(X_under, y_under), 0]})\n",
    "\n",
    "# Decision Tree\n",
    "dtree = DecisionTreeClassifier(random_state = 31)\n",
    "dtree.fit(X_under,y_under)\n",
    "dtree.score(X_under, y_under)\n",
    "\n",
    "dtree_cv = cross_val_score(dtree, X_train, y_train, cv=5, scoring= 'accuracy')\n",
    "np.average(dtree_cv)\n",
    "\n",
    "results.update({'DecisionTree': [dtree.score(X_under, y_under), np.average(dtree_cv)]})\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_jobs=-1, bootstrap=True, random_state=31)\n",
    "rf.fit(X_under, y_under);\n",
    "rf.score(X_under, y_under)\n",
    "\n",
    "rf_cv = cross_val_score(rf, X_train, y_train, cv=5, scoring= 'accuracy', n_jobs = 8, verbose = 1)\n",
    "np.average(rf_cv)\n",
    "\n",
    "results.update({'RandomForest': [rf.score(X_under, y_under), np.average(rf_cv)]})\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_under, y_under)\n",
    "gbc.score(X_under, y_under)\n",
    "\n",
    "gbc_cv = cross_val_score(gbc, X_train, y_train, cv=5, scoring= 'accuracy', n_jobs = 8, verbose = 1)\n",
    "np.average(gbc_cv)\n",
    "\n",
    "results.update({'GradientBoosting': [gbc.score(X_under, y_under), np.average(gbc_cv)]})\n",
    "\n",
    "# Ada Boost\n",
    "dc = DecisionTreeClassifier(class_weight='balanced')\n",
    "ada = AdaBoostClassifier(base_estimator = dc, random_state=31)\n",
    "ada.fit(X_under, y_under)\n",
    "ada.score(X_under, y_under)\n",
    "\n",
    "ada_cv = cross_val_score(ada, X_train, y_train, cv=5, scoring= 'accuracy', n_jobs = 8, verbose = 1)\n",
    "np.average(ada_cv)\n",
    "\n",
    "results.update({'Ada-DT': [ada.score(X_under, y_under), np.average(ada_cv)]})\n",
    "\n",
    "\n",
    "#SVC\n",
    "svc = SVC(C=.1, kernel = 'sigmoid', max_iter=1000)\n",
    "svc.fit(X_under, y_under)\n",
    "svc.score(X_under, y_under)\n",
    "\n",
    "svc_cv = cross_val_score(svc, X_train, y_train, cv=5, n_jobs = 8, verbose = 1)\n",
    "np.average(svc_cv)\n",
    "\n",
    "results.update({'SVC': [svc.score(X_under, y_under), np.average(svc_cv)]})\n",
    "\n",
    "# MLP Classifier\n",
    "mlp = MLPClassifier(random_state=31, max_iter=10000, hidden_layer_sizes=(500,))\n",
    "mlp.fit(X_under, y_under)\n",
    "mlp.score(X_under, y_under)\n",
    "\n",
    "mlp_cv = cross_val_score(mlp, X_train, y_train, cv=5, n_jobs = 8, verbose = 1)\n",
    "mlp_cv\n",
    "\n",
    "results.update({'MLP': [mlp.score(X_under, y_under), np.average(mlp_cv)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Results\n",
    "pd.DataFrame(results, columns = results.keys()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After reviewing the results, Random Forest is selected and then tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and calculate cross validation score\n",
    "rf = RandomForestClassifier(n_jobs=-1, bootstrap=True, random_state=31)\n",
    "rf.fit(X_under, y_under);\n",
    "rf.score(X_train, y_train)\n",
    "\n",
    "rf_cv = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy', n_jobs = 8, verbose = 1)\n",
    "np.average(rf_cv)\n",
    "\n",
    "# Review confusion matrix\n",
    "rf_cm = ConfusionMatrix(rf, classes=['FF', 'CH', 'MM'])\n",
    "\n",
    "rf_cm.fit(X_under, y_under)\n",
    "rf_cm.score(X_train, y_train)\n",
    "\n",
    "rf_cm.show(outpath = '../viz/rf__under_matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross validation plots\n",
    "# Capture cv params in dictionary\n",
    "\n",
    "params = {'n_estimators': ['n_estimators', [1, 3, 5, 7, 9, 11, 13, 15, 20, 25, 30]],\n",
    "          'max_depth': ['max_depth', [2, 5, 10, 15, 20, 25]], \n",
    "          'min_samples_split': ['min_samples_split', [5, 10, 50, 100, 250, 500]], \n",
    "          'min_samples_leaf': ['min_samples_leaf', [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]], \n",
    "          'max_leaf_nodes': ['max_leaf_nodes', [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000,\n",
    "                                               1025, 1000, 1750, 2000, 3000, 4000, 5000, 10000, 20000]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = rf,\n",
    "                      X = X_under,\n",
    "                      y = y_under,\n",
    "                      param_name = params['n_estimators'][0],\n",
    "                      param_range = params['n_estimators'][1],\n",
    "                      cv = 5,\n",
    "                      verbose = 1,\n",
    "                      n_jobs = 4,\n",
    "                      logx = False)\n",
    "                                             \n",
    "viz.fit(X_under, y_under)\n",
    "viz.show(outpath = '../viz/n_estimators');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = rf,\n",
    "                      X = X_under,\n",
    "                      y = y_under,\n",
    "                      param_name = params['max_depth'][0],\n",
    "                      param_range = params['max_depth'][1],\n",
    "                      cv = 5,\n",
    "                      verbose = 1,\n",
    "                      n_jobs = 8,\n",
    "                      logx = False)\n",
    "\n",
    "# Size, fit, and show visualization\n",
    "viz.fit(X_under, y_under)\n",
    "viz.show(outpath = '../viz/max_depth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = rf,\n",
    "                      X = X_under,\n",
    "                      y = y_under,\n",
    "                      param_name = params['min_samples_split'][0],\n",
    "                      param_range = params['min_samples_split'][1],\n",
    "                      cv = 5,\n",
    "                      verbose = 1,\n",
    "                      n_jobs = 8,\n",
    "                      logx = False)\n",
    "\n",
    "# Size, fit, and show visualization\n",
    "viz.fit(X_under, y_under)\n",
    "viz.show(outpath = '../viz/min_samp_split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_leaf\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = rf,\n",
    "                      X = X_under,\n",
    "                      y = y_under,\n",
    "                      param_name = params['min_samples_leaf'][0],\n",
    "                      param_range = params['min_samples_leaf'][1],\n",
    "                      cv = 5,\n",
    "                      verbose = 1,\n",
    "                      n_jobs = 8,\n",
    "                      logx = False)\n",
    "\n",
    "# Size, fit, and show visualization\n",
    "viz.fit(X_under, y_under)\n",
    "viz.show(outpath = '../viz/min_samp_leaf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_leaf_nodes\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = rf,\n",
    "                      X = X_under,\n",
    "                      y = y_under,\n",
    "                      param_name = params['max_leaf_nodes'][0],\n",
    "                      param_range = params['max_leaf_nodes'][1],\n",
    "                      cv = 5,\n",
    "                      verbose = 1,\n",
    "                      n_jobs = 8,\n",
    "                      logx = False)       \n",
    "\n",
    "# Size, fit, and show visualization\n",
    "viz.fit(X_under, y_under)\n",
    "viz.show(outpath = '../viz/max_leaf_nodes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tuned model\n",
    "rft = RandomForestClassifier(n_estimators=15,\n",
    "                             max_depth=20,\n",
    "                             min_samples_split=100,\n",
    "                             min_samples_leaf=40, \n",
    "                             max_leaf_nodes=12500,\n",
    "                             random_state=31,\n",
    "                             verbose=1,\n",
    "                             n_jobs=8)\n",
    "\n",
    "rft.fit(X_under, y_under);\n",
    "rft.score(X_train, y_train)\n",
    "\n",
    "# CV for tuned model\n",
    "rft_cv = cross_val_score(rft, X_train, y_train, cv=10, scoring='accuracy', n_jobs = 8, verbose = 1)\n",
    "np.average(rft_cv)\n",
    "\n",
    "# Confusion matrix for tuned model\n",
    "rft_cm = ConfusionMatrix(rft, classes=['FF', 'CH', 'MM'])\n",
    "\n",
    "rft_cm.fit(X_train, y_train)\n",
    "rft_cm.score(X_test, y_test)\n",
    "\n",
    "rft_cm.show(outpath = '../viz/rf_tuned_matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Assessment vs Niave Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict each pitchers pitches against the model and save to dictionary\n",
    "total = len(models.keys())\n",
    "count = 1\n",
    "\n",
    "for pitcher in unique_pitchers:\n",
    "    pitcher_df = pitches.loc[pitches.pitcher_id == pitcher]\n",
    "    y_pitcher = list(pitcher_df.pitch_type)\n",
    "    pitcher_df = pitcher_df.drop(columns=['pitcher_id', 'pitch_type'])\n",
    "    score = rft.score(pitcher_df, y_pitcher)\n",
    "    preds = rft.predict(pitcher_df)\n",
    "    models.update({pitcher: [score, y_pitcher, preds]})\n",
    "    \n",
    "    print('Just processed {}.  {} of {} pitchers remaining'.format(pitcher, count, total), end='\\r')\n",
    "    count += 1\n",
    "    \n",
    "# Please note, the naive model calculations are long and not included here.\n",
    "# See 6.02 notebook for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per pitch, create seaborn distplot of model performance vs naive model\n",
    "# Code below addresses fastballs\n",
    "sns.set(rc={'figure.figsize':(20, 10)}, font_scale=2)\n",
    "plt.axvline(0)\n",
    "\n",
    "ff_dist = sns.distplot(final_results_ff['ff_model_less_n'], bins = 18, kde=False, color='darkblue')\n",
    "ff_dist.set(title='Model Performance vs. Naive Model with Fastballs', );\n",
    "\n",
    "plt.xlabel('Model Minus Naive Prediction (% difference)')\n",
    "plt.ylabel('Total Pitchers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
