{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting All Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "from yellowbrick.features import RadViz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../data/train_test_split/'\n",
    "\n",
    "infile = open(filepath + 'X_train_ac.pickle','rb')\n",
    "X_train_full = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(filepath + 'X_test_ac.pickle','rb')\n",
    "X_test_real = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(filepath + 'y_train_ac.pickle','rb')\n",
    "y_train_full = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open(filepath + 'y_test_ac.pickle','rb')\n",
    "y_test_real = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full,\n",
    "                                                    y_train_full,\n",
    "                                                    test_size = .5,\n",
    "                                                    random_state = 31,\n",
    "                                                    shuffle = True,\n",
    "                                                    stratify = y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train).reshape(-1, ).astype('int')\n",
    "y_test = np.array(y_test).reshape(-1, ).astype('int')\n",
    "y_test_real = np.array(y_test_real).reshape(-1, ).astype('int')\n",
    "# y_train_2c = np.array(y_train_2c).reshape(-1, )\n",
    "# y_train_3c = np.array(y_train_3c).reshape(-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC for all types of pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=31, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      389723.9432           58.85m\n",
      "         2      388069.2373           59.44m\n",
      "         3      386608.7432           59.14m\n",
      "         4 2247829298733610225834655744.0000           58.38m\n",
      "         5 2247829298733610225834655744.0000           57.61m\n",
      "         6 2247829298733610225834655744.0000           57.00m\n",
      "         7 2247829298733610225834655744.0000           56.96m\n",
      "         8 2247829298733610225834655744.0000           56.39m\n",
      "         9 2247829298733610225834655744.0000           56.13m\n",
      "        10 2247829298733610225834655744.0000           55.43m\n"
     ]
    }
   ],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(gbc, X_train, y_train, cv=5, scoring= 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [.0001, .001, .01, .1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'learning_rate', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 10, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/learning');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [2, 3, 4, 5, 10]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'max_depth', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/max_depth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [5, 10] + list(range(25, 1200, 25))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'min_samples_split', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/min_samples_split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = range(25, 1000, 25)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'min_samples_leaf', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/min_samples_leaf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = range(2, 47)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'max_features', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/max_features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = range(50, 800, 50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'max_leaf_nodes', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/max_leaf_nodes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [1, 2, 3, 4] + list(range(5, 50, 5))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'n_estimators', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/n_estimators');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [.001, .005, .01, .05, .75, 1, 1.25, 1.5]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "viz = ValidationCurve(model = gbc, \n",
    "                                 X = X_train,\n",
    "                                 y = y_train,\n",
    "                                 param_name = 'subsample', ## this is the way for accessing a parameter of a \n",
    "                                                                                        #transformer within pipeline\n",
    "                                 param_range = parameters, \n",
    "                                 cv = 5, ## note that this can take too long if your data is big\n",
    "                                 verbose = 1, # algorithms will update us about the progress\n",
    "                                 n_jobs = -1, # we will be using the other processing units in parallel\n",
    "                                 logx = False \n",
    "                                )\n",
    "                                             \n",
    "\n",
    "# Fit and show the visualizer\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath = '../viz/subsample');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DecisionTreeClassifier(max_depth=7, class_weight='balanced', max_features=10)\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=dc, n_estimators=2000, learning_rate=.01, random_state=31)\n",
    "\n",
    "cv = cross_validate(ada, X_train, y_train, cv=5, n_jobs=-1, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = cv['estimator'][1]\n",
    "iris_cm = ConfusionMatrix(mod, classes=['Fastball', 'Cutter', 'Two-seam', 'Slider', 'Curve', 'Changeup'])\n",
    "\n",
    "iris_cm.fit(X_train, y_train)\n",
    "iris_cm.score(X_test, y_test)\n",
    "\n",
    "iris_cm.show(outpath = '../viz/testing_matrix');\n",
    "print(cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=.1, kernel = 'sigmoid', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_train, y_train)\n",
    "\n",
    "cv = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Tested ranges\n",
    "\n",
    "# params = {'min_samples_split': [2, range(5, 1000, 5)]}\n",
    "\n",
    "## Model based on analysis from yellowbrick cv graphs\n",
    "# gbc2 = GradientBoostingClassifier(learning_rate=.01, \n",
    "#                                   max_depth=5, \n",
    "#                                   max_features=2, \n",
    "#                                   min_samples_leaf=775, \n",
    "#                                   min_samples_split=200, \n",
    "#                                   n_estimators=30,\n",
    "#                                   subsample=.75,\n",
    "#                                   random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc2 = GradientBoostingClassifier()\n",
    "\n",
    "params = {'subsample': [.001, .005, .01, .05, .75, 1, 1.25, 1.5],\n",
    "          'n_estimators': [1, 2, 3, 4, range(5, 50, 5)],\n",
    "          'criterion': ['friedman_mse', 'mse', 'mae'], \n",
    "          'max_leaf_nodes': range(50, 800, 50),\n",
    "          'max_features': range(2, 47), \n",
    "          'learning_rate': [.0001, .001, .01, .1], \n",
    "          'max_depth': [2, 3, 4, 5, 10], \n",
    "          'min_samples_leaf': range(25, 1000, 25), \n",
    "          'min_samples_split': [2, 5, 10, range(25, 1200, 25)]}\n",
    "\n",
    "rs = RandomizedSearchCV(gbc2, params, n_jobs=-1, random_state=31, cv=5, verbose = 1, n_iter=10000, refit=True)\n",
    "\n",
    "rs.fit(X_train, y_train);\n",
    "\n",
    "rs.best_params_, rs.score(X_train, y_train), rs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_cm = ConfusionMatrix(rs, classes=['Fastball', 'Cutter', 'Slider', 'Curve', 'Changeup'])\n",
    "\n",
    "rs_cm.fit(X_train, y_train)\n",
    "rs_cm.score(X_test, y_test)\n",
    "\n",
    "rs_cm.show(outpath = '../viz/rs_matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcb = GradientBoostingClassifier(subsample=0.001, \n",
    "                                  n_estimators=3, min_samples_leaf=425, max_leaf_nodes=150, \n",
    "                                  min_samples_split= 5,\n",
    "                                  max_features=16, \n",
    "                                  max_depth=2, \n",
    "                                  learning_rate = 0.0001,\n",
    "                                  criterion ='mse', \n",
    "                                  random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_cm = ConfusionMatrix(gbc, classes=['Fastball', 'Cutter', 'Slider', 'Curve', 'Changeup'])\n",
    "\n",
    "iris_cm.fit(X_train, y_train)\n",
    "iris_cm.score(X_test, y_test)\n",
    "\n",
    "iris_cm.show(outpath = '../viz/default_matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "Code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y_train = label_binarize(y_train, classes=[0, 1, 2, 3, 4])\n",
    "y_test = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
    "n_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(gbc)\n",
    "\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Learn to predict each class against the other\n",
    "# classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "#                                  random_state=31))\n",
    "\n",
    "# y_score = classifier.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(15,11))\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('../viz/roc_one_vs_rest.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.figure(figsize=(15,11))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('../viz/roc_mc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=31, max_iter=10000, hidden_layer_sizes=(500,))\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train), clf.score(X_test, y_test)\n",
    "# clf.predict_proba(X_test[:1])\n",
    "\n",
    "# clf.predict(X_test[:5, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'hidden_layer_sizes': [(100,), (200,), (300,), (500,), (1000,)],\n",
    "          'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "          'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "          'alpha': [0.0001, .001, .01, 1],\n",
    "          'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "          'learning_rate_init': [0.001, 0.01, .1, 1]}\n",
    "\n",
    "rsmlp = RandomizedSearchCV(estimator = clf, \n",
    "                           param_distributions = params, \n",
    "                           n_iter = 5000, \n",
    "                           n_jobs = -1, \n",
    "                           cv = 5, \n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.fit(X_train, y_train);\n",
    "rsmlp.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.error_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsmlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
